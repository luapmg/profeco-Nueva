{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MILK        SERVIDOR </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Importar Librerias</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import csv\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from multiprocessing import Process\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Manager\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Cargamos los datos</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/paul/Documentos/Nuevas Tablas Profeco 2016/xxx/all_milk_xxx.csv', encoding='utf8',  \n",
    "                 names=['producto','presentacion','marca','categoria','precio','fechaRegistro','cadenaComercial', \n",
    "                          'giro','nombreComercial','direccion','estado','municipio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Reordenamos el dataFrame</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['producto','presentacion','marca','categoria','cadenaComercial','giro','nombreComercial','direccion','estado',\n",
    "        'municipio','fechaRegistro','precio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.iloc[:, 0:10].values\n",
    "y_train = df.iloc[:, 10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comenzamos a Procesar los Datos</b>\n",
    "<p>Convertimos las string a tipo datetime con pandas</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fechaRegistro'] = pd.to_datetime(df['fechaRegistro'], format='%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comenzando a tratar las fechas</b>\n",
    "<p>Creamos nuevas variables a partir de las fechas mediante pandas</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = df['fechaRegistro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = df['fechaRegistro']\n",
    "over_time = pd.DataFrame({'year': datetimes.dt.year,\n",
    "                          \"month\": datetimes.dt.month,\n",
    "                          \"day\": datetimes.dt.day,\n",
    "                          \"dayofweek\": datetimes.dt.dayofweek,\n",
    "                          \"dayofyear\": datetimes.dt.dayofyear,\n",
    "                          \"weekofyear\": datetimes.dt.weekofyear,\n",
    "                          \"quarter\": datetimes.dt.quarter,\n",
    "                          \"hour\":datetimes.dt.hour,\n",
    "                          \"minute\":datetimes.dt.minute,\n",
    "                          \"second\":datetimes.dt.second,\n",
    "                          \n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = int(len(X_train)/4)\n",
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = []\n",
    "def f1(q):\n",
    "    for i in range(0, aux):\n",
    "        time1.append([over_time['year'][i], over_time['month'][i], over_time['day'][i], over_time['dayofweek'][i], \n",
    "                     over_time['dayofyear'][i], over_time['weekofyear'][i], over_time['quarter'][i],\n",
    "                    over_time['hour'][i], over_time['minute'][i]])\n",
    "    q.put(time1)\n",
    "    #return time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2 = []\n",
    "def f2(q):\n",
    "    for i in range(aux, (aux*2)):\n",
    "        time2.append([over_time['year'][i], over_time['month'][i], over_time['day'][i], over_time['dayofweek'][i], \n",
    "                     over_time['dayofyear'][i], over_time['weekofyear'][i], over_time['quarter'][i],\n",
    "                    over_time['hour'][i], over_time['minute'][i]])\n",
    "    q.put(time2)\n",
    "    #return time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time3 = []\n",
    "def f3(q):\n",
    "    for i in range((aux*2), (aux*3)):\n",
    "        time3.append([over_time['year'][i], over_time['month'][i], over_time['day'][i], over_time['dayofweek'][i], \n",
    "                     over_time['dayofyear'][i], over_time['weekofyear'][i], over_time['quarter'][i],\n",
    "                    over_time['hour'][i], over_time['minute'][i]])\n",
    "    q.put(time3)\n",
    "    #return time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time4 = []\n",
    "def f4(q):\n",
    "    for i in range((aux*3), len(datetimes)):\n",
    "        time4.append([over_time['year'][i], over_time['month'][i], over_time['day'][i], over_time['dayofweek'][i], \n",
    "                     over_time['dayofyear'][i], over_time['weekofyear'][i], over_time['quarter'][i],\n",
    "                    over_time['hour'][i], over_time['minute'][i]])\n",
    "    q.put(time4)\n",
    "    #return time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO MOVER\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "time1 = []\n",
    "time2 = []\n",
    "time3 = []\n",
    "time4 = []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    q1 = Queue()\n",
    "    q2 = Queue()\n",
    "    q3 = Queue()\n",
    "    q4 = Queue()\n",
    "    p1 = Process(target=f1, args=(q1,))\n",
    "    p2 = Process(target=f2, args=(q2,))\n",
    "    p3 = Process(target=f3, args=(q3,))\n",
    "    p4 = Process(target=f4, args=(q4,))\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p3.start()\n",
    "    p4.start()\n",
    "    time1 = q1.get()    # prints \"[42, None, 'hello']\"\n",
    "    time2 = q2.get()    # prints \"[42, None, 'hello']\"\n",
    "    time3 = q3.get()    # prints \"[42, None, 'hello']\"\n",
    "    time4 = q4.get()    # prints \"[42, None, 'hello']\"\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    p3.join()\n",
    "    p4.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = time1 + time2 + time3 + time4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = None\n",
    "time2 = None\n",
    "time3 = None\n",
    "time4 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#No modificar\n",
    "time = []\n",
    "for i in range(0, len(datetimes)):\n",
    "    time.append([over_time['year'][i], over_time['month'][i], over_time['day'][i], over_time['dayofweek'][i], \n",
    "                 over_time['dayofyear'][i], over_time['weekofyear'][i], over_time['quarter'][i],\n",
    "                over_time['hour'][i], over_time['minute'][i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Metemos todas las variables a columnas indicadas por las cabeceras de la base de datos</b>\n",
    "<p>Hacemos uso de diccionarios y de nuevo de el DataFrame de pandas</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = {}\n",
    "for i in range(0, len(df.axes[1])-2):\n",
    "    column[df.axes[1][i]] = X_train[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_column = {}\n",
    "lb = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['producto'] = lb.fit_transform(df['producto']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['presentacion'] = lb.fit_transform(df['presentacion']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['marca'] = lb.fit_transform(df['marca']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['categoria'] = lb.fit_transform(df['categoria'].astype(str)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cadenaComercial'] = lb.fit_transform(df['cadenaComercial']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['giro'] = lb.fit_transform(df['giro']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nombreComercial'] = lb.fit_transform(df['nombreComercial']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['direccion'] = lb.fit_transform(df['direccion']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['estado'] = lb.fit_transform(df['estado'].astype(str)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['municipio'] = lb.fit_transform(df['municipio'].astype(str)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('/home/paul/Documentos/Nuevas Tablas Profeco 2016/Xdesings/Xdesing_milk_direcciones.csv', 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row in df['direccion']:\n",
    "        spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escribir_producto():\n",
    "    with open('/home/paul/Documentos/Nuevas Tablas Profeco 2016/Xdesings/Xdesing_milk_producto.csv', 'w') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in df['producto']:\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escribir_presentacion():\n",
    "    with open('/home/paul/Documentos/Nuevas Tablas Profeco 2016/Xdesings/Xdesing_milk_presentacion.csv', 'w') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in df['presentacion']:\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escribir_marca():\n",
    "    with open('/home/paul/Documentos/Nuevas Tablas Profeco 2016/Xdesings/Xdesing_milk_marca.csv', 'w') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in df['marca']:\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escribir_categoria():\n",
    "    with open('/home/paul/Documentos/Nuevas Tablas Profeco 2016/Xdesings/Xdesing_milk_categoria.csv', 'w') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in df['categoria']:\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escribir_cadenaComercial():\n",
    "    with open('/home/paul/Documentos/Nuevas Tablas Profeco 2016/Xdesings/Xdesing_milk_cadenaComercial.csv', 'w') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in df['cadenaComercial]:\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escribir_giro():\n",
    "    with open('/home/paul/Documentos/Nuevas Tablas Profeco 2016/Xdesings/Xdesing_milk_giro.csv', 'w') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in df['giro']:\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escribir_nombreComercial():\n",
    "    with open('/home/paul/Documentos/Nuevas Tablas Profeco 2016/Xdesings/Xdesing_milk_nombreComercial.csv', 'w') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in df['nombreComercial']:\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escribir_estado():\n",
    "    with open('/home/paul/Documentos/Nuevas Tablas Profeco 2016/Xdesings/Xdesing_milk_estado.csv', 'w') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in df['estado']:\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escribir_municipio():\n",
    "    with open('/home/paul/Documentos/Nuevas Tablas Profeco 2016/Xdesings/Xdesing_milk_municipio.csv', 'w') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in df['municipio']:\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mandamos escribir todas las columnas ya binarizadas(menos direcion que ya la tengo en disco)\n",
    "if __name__ == '__main__':\n",
    "   \n",
    "    p1 = Process(target=escribir_producto)\n",
    "    p2 = Process(target=escribir_presentacion)\n",
    "    p3 = Process(target=escribir_marca)\n",
    "    p4 = Process(target=escribir_categoria)\n",
    "    p5 = Process(target=escribir_cadenaComercial)\n",
    "    p6 = Process(target=escribir_giro)\n",
    "    p7 = Process(target=escribir_nombreComercial)\n",
    "    p8 = Process(target=escribir_estado)\n",
    "    p9 = Process(target=escribir_municipio)\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p3.start()\n",
    "    p4.start()\n",
    "    p5.start()\n",
    "    p6.start()\n",
    "    p7.start()\n",
    "    p8.start()\n",
    "    p9.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    p3.join()\n",
    "    p4.join()\n",
    "    p5.join()\n",
    "    p6.join()\n",
    "    p7.join()\n",
    "    p8.join()\n",
    "    p9.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Binarizamos todas las columnas que son strings y se trataran como etiquetas</b>\n",
    "<ul>\n",
    "  <li>Hacemos uso de Herramientas de sklearn.preprocessing</li>\n",
    "  <li>Seguimos usando el DataFrame de pandas para el manejo de las columnas</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdesing = []\n",
    "for i in range(0, len(X_train)):\n",
    "    Xdesing.append(df['producto'][i] + df['presentacion'][i]+ df['marca'][i] \n",
    "                  + df['categoria'][i] + df['cadenaComercial'][i] + df['giro'][i]\n",
    "                  + df['direccion'][i] + df['estado'][i] + df['municipio'][i] \n",
    "                  + time[i])\n",
    "Xdesing = np.asarray(Xdesing)\n",
    "y = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "binarized_column = {}\n",
    "lb = LabelBinarizer()\n",
    "for i in range(0, len(df.axes[1])-2):\n",
    "    binarized_column[df.axes[1][i]] = lb.fit_transform(column[df.axes[1][i]]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creamos la matriz de Dise√±o</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xdesing = []\n",
    "for i in range(0, len(X_train)):\n",
    "    Xdesing.append(binarized_column['producto'][i] + binarized_column['presentacion'][i]+ binarized_column['marca'][i] \n",
    "                  + binarized_column['categoria'][i] + binarized_column['cadenaComercial'][i] + binarized_column['giro'][i]\n",
    "                  + binarized_column['direccion'][i] + binarized_column['estado'][i] + binarized_column['municipio'][i] \n",
    "                  + time[i])\n",
    "Xdesing = np.asarray(Xdesing)\n",
    "y = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdesing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('/home/paul/Documentos/Nuevas Tablas Profeco 2016/Xdesings/Xdesing_milk.csv', 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row in Xdesing:\n",
    "        spamwriter.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
